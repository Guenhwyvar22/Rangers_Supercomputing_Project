import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

# Define the Navajo to English dictionary
navajo_dictionary = {
    "Yá'át'ééh": "hello",
    "hagoone": "goodbye",
    "la'a": "ok",
    "ah'he'hee": "thank you"
}

# Create training data
navajo_words = list(navajo_dictionary.keys())
english_translations = list(navajo_dictionary.values())

# Tokenize the words
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(navajo_words)

# Convert text to sequences
sequences = tokenizer.texts_to_sequences(navajo_words)

# Define the model
model = Sequential([
    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=1),
    LSTM(8),
    Dense(len(english_translations), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x=sequences, y=tf.range(len(english_translations)), epochs=100)

# Get user input
user_input = input("Enter a Navajo word: ")

# Convert user input to sequence
user_sequence = tokenizer.texts_to_sequences([user_input])[0]

# Predict the English translation
prediction = model.predict(tf.convert_to_tensor(user_sequence))

# Find the index with the highest probability
predicted_index = tf.argmax(prediction).numpy()

# Display the result
if predicted_index < len(english_translations):
    translated_word = english_translations[predicted_index]
    print(f"The English translation of '{user_input}' is '{translated_word}'.")
else:
    print("Translation not found.")
